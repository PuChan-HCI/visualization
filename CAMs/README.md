# GradCAMで深層学習モデルの判断根拠を可視化

深層学習は，画像認識や自然言語処理など，さまざまな分野で高い性能を示しており，幅広く活用されている．しかし，深層学習モデルは構造が非常に複雑であるため，なぜそのような判断を下したのかを人間が理解することは容易ではない．いわゆる「ブラックボックス」としての性質が課題となっている．

この問題に対応するため，近年ではXAI（Explainable AI：説明可能な人工知能）と呼ばれる技術が注目されている．XAIとは，機械学習モデルの判断根拠を人間にとって理解しやすい形で可視化・説明するための技術である．

XAIの代表的な手法の一つに，GradCAM（Gradient-weighted Class Activation Mapping）がある．GradCAMは，画像分類モデルが入力画像のどの部分に注目して判断を行っているかを視覚的に示すことができる．これにより，モデルの判断過程を直感的に理解することが可能となる．

[Source](https://www.codemajin.net/visualize-prediction-of-cnn-with-gradcam/)

## XAIが必要とされる理由
XAI（Explainable AI：説明可能なAI）は，以下のような観点からその重要性が指摘されている．
- 信頼性の向上：AIの判断理由を可視化・説明可能にすることで，ユーザはAIの出力に対してより高い信頼を寄せることができるようになる．
- 責任性の確保：AIが誤った判断を下した場合でも，その根拠や原因を特定することが可能となり，適切な修正や再学習が可能となる．
- 規制への対応：AIの利用に関する規制が各国で強化されつつある中，XAIはモデルの透明性を確保し，法的・倫理的な要件を満たす手段として有効である．

## XAIの活用例:
XAIの技術は，さまざまな応用分野で活用されており，以下のような事例が報告されている．
- 医療診断：診断支援AIにおいて，モデルの判断根拠を医師に提示することで，診断精度の向上や誤診の防止に寄与する．
- 金融分野：融資審査モデルの判断理由を顧客に説明することにより，透明性が向上し，顧客満足度の向上に繋がる．
- 自動運転：自律走行車の挙動について，なぜ特定の判断（例：停止や回避）を行ったのかを説明することで，ユーザの安心感やシステムの信頼性向上が期待される．

## CAM（Class Activation Map）について
まず，Grad-CAMの基盤となるアルゴリズムであるCAM（Class Activation Map）について解説する．CAMは，画像分類タスクにおける畳み込みニューラルネットワーク（CNN）に特化した説明可能なAI（XAI）の手法であり，モデルの判断根拠を視覚的に示すことが可能である．

CAMの動作は以下の3つのステップに分けられる．
1. 特徴の抽出：入力画像は，CNNの畳み込み層により処理され，各層で様々な空間的特徴が抽出される．その後，Global Average Pooling（GAP）層を通じて，各特徴マップの平均値が算出され，次の全結合層に入力される．
2. 重要度の計算：各特徴マップの重要度は，全結合層における重み係数により定まる．この重みは，学習過程で最適化され，それぞれの特徴が分類結果にどの程度寄与しているかを示す指標となる．
3. ヒートマップの作成：算出された特徴マップとその重要度に基づき，入力画像と同じサイズのヒートマップを生成する．ヒートマップにおいて明るい（高強度の）領域は，モデルがその領域に注目して判断を下したことを示している．

このようにCAMは，CNNベースの画像分類モデルにおける判断根拠の可視化を可能にすることで，モデルの挙動を直感的に理解する手段を提供する．

![GradCam](https://www.codemajin.net/wp-content/uploads/2024/12/CAMの原理.png)

## GradCAM （Gradient-weighted Class Activation Mapping）について

前述のように，CAMはGlobal Average Pooling（GAP）を用いた特定の構造を持つ畳み込みニューラルネットワーク（CNN）にのみ適用可能であるという制約がある．この制約を克服するために提案されたのがGrad-CAM（Gradient-weighted Class Activation Mapping）であり，全結合層の重み係数の代わりに勾配情報を用いることで，より一般的なCNNアーキテクチャに対しても可視化を可能としている．

Grad-CAMの動作は，以下のような手順で構成される．
1. 順伝播（Forward Pass）：入力画像をCNNに入力し，最終的な出力（たとえば，あるクラスに属する確率）を得る．
2. 逆伝播（Backward Pass）：最終出力に対して，関心のある特定クラス（例：「猫」）に関する損失関数の勾配を計算する．この勾配は，どの特徴マップ（畳み込み層の出力）がそのクラスに貢献したかを特定するために使用される．
3. 重み付け：各特徴マップに対して，その勾配の空間平均を計算し，これをその特徴マップに対応する重みとして用いる．この重みは，特徴マップが出力クラスに与えた寄与の度合いを示す．
4. ヒートマップの生成：得られた重み付き特徴マップを線形結合し，ReLU関数を適用することで，最終的なヒートマップを生成する．このヒートマップは，入力画像中で予測に最も寄与した領域を視覚的に示すものである．

![GradCam](https://www.codemajin.net/wp-content/uploads/2024/12/Grad-CAMの原理.png)

実装：[GradCam](https://github.com/jacobgil/pytorch-grad-cam)
